% Template for ICIP-2018 paper; to be used with:
%          spconf.sty  - ICASSP/ICIP LaTeX style file, and
%          IEEEbib.bst - IEEE bibliography style file.
% --------------------------------------------------------------------------
\documentclass{article}


\usepackage{spconf,amsmath,graphicx}
\usepackage{epstopdf}
\usepackage{amssymb}


\usepackage[linesnumbered,ruled,vlined]{algorithm2e}
\usepackage{algpseudocode}
\usepackage{amsmath}

\usepackage{color}
\renewcommand{\algorithmicrequire}{\textbf{Input:}}
\renewcommand{\algorithmicensure}{\textbf{Output:}}



\newcommand{\comments}[1]{}
\newcommand{\cxj}[1]{\textcolor[rgb]{1.00,0.00,0.00}{(xuejin:#1)}}
\newcommand{\xjmd}[1]{\textcolor[rgb]{0.00,0.00,1.00}{#1}}

\newcommand{\para}[1]{\noindent\textbf{#1}}
\newcommand{\wxx}[1]{\textcolor[rgb]{1.00,0.00,1.00}{(wxx:#1)}}
%%%% definitions
\newcommand{\ptset} {\mathbb{P}}

\makeatletter
    \newcommand\fcaption{\def\@captype{figure}\caption}
\makeatother
% Example definitions.
% --------------------
\def\x{{\mathbf x}}
\def\L{{\cal L}}

% Title.
% ------
\title{SketchPointNet: A compact network for robust sketch recognition}
%
% Single address.
% ---------------
\name{Paper 1938}
\address{ }
%
% For example:
% ------------
%\address{School\\
%	Department\\
%	Address}
%
% Two addresses (uncomment and modify for two-address case).
% ----------------------------------------------------------
%\twoauthors
%  {A. Author-one, B. Author-two\sthanks{Thanks to XYZ agency for funding.}}
%	{School A-B\\
%	Department A-B\\
%	Address A-B}
%  {C. Author-three, D. Author-four\sthanks{The fourth author performed the work
%	while at ...}}
%	{School C-D\\
%	Department C-D\\
%	Address C-D}
%
\begin{document}
%\ninept
%
\maketitle
%
\begin{abstract}
Sketch recognition has been studied for many years. 
With the great success of deep networks on image recognition, we propose a novel point-based network, named SketchPointNet, which is both robust and compact for sketch recognition. 
%
Sketch features are hierarchically learned from three mini PointNets, by successively grouping 2D points in a bottom-up fashion. 
%
Our SketchPointNet takes both temporal and spatial information in strokes into account during point sampling and grouping.
%
Because it directly consumes the sparse points, our SketchPointNet is very compact and efficient. 
%
Compared with state-of-the-art techniques, SketchPointNet achieves comparable performance on the challenging TU-Berlin dataset while significantly reduces the number of network parameters. 

 
\end{abstract}

\begin{keywords}
Sketch recognition, point set, deep neural network, stroke pattern 
\end{keywords}

\input{introduction}
\input{approach}
\input{experiments}
\input{conclusion}
\bibliographystyle{IEEEbib}
\bibliography{strings,refs}

\end{document}
