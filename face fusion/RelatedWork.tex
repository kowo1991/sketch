\section{Related work}

In this section, we summarize existing face editing techniques that are related to our work.

<<<<<<< HEAD
\noindent\textbf{Face Morphing.} Face morphing is commonly referred as a smooth animated transformation of one digital face image to another.
In most cases, the background of the face image is pure in order to make us focus on transition itself.
\cxj{The morphing problem has nothing related with background. The background can be easily removed by face detection. }

Beier and Neely \cite{fbim} developed a user interface to build the correspondences of two faces by a group of line pairs.
The procedure of building correspondences of two faces is tedious and time-consuming. Besides, hand-marked features are not precise. After building correspondences, the corresponding pixels are linearly interpolated.
Wolberg \cite{wol} proposed a mesh-based method to build the correspondences of two faces.
=======
\noindent\textbf{Face Morphing.} Face morphing is commonly referred as a smooth animated transformation of one digital face image to another. 
In most cases, the background of the face image is pure in order to make us focus on transition itself. 
\cxj{The morphing problem has nothing related with background. The background can be easily removed by face detection. }

Beier and Neely \cite{fbim} developed a user interface to build the correspondences of two faces by a group of line pairs. 
The procedure of building correspondences of two faces is tedious and time-consuming. Besides, hand-marked features are not precise. After building correspondences, the corresponding pixels are linearly interpolated.  
Wolberg \cite{wol} proposed a mesh-based method to build the correspondences of two faces. 
>>>>>>> origin/master
The correspondences of two faces are referred as meshes instead of line pairs. Karungaru et al. \cite{mhf} detected five feature points as control points, then segmented face images into several triangles according to control points, next warped the face images according to corresponding triangles. These face morphing methods have a different way in building correspondences. Their aim is creating a seamless transition from one face to the other.

 In fact, face morphing is a seamless transition from one face image to the other. In other words, it is a transition of two images. It builds the correspondences of two faces, but not adjusts the sizes and the locations of two faces. It warps two images according to the correspondences and interpolates two warped images to generate intermediate images. So the intermediate images of the transition are not photorealistic. Our algorithm adjusts  the sizes and the locations of two faces. It operates only on two faces but not the whole images, and preserves lots of illumination information and facial hues of the target face. So the result of our algorithm is a photorealistic edited target face but not a transition of two images.

\noindent\textbf{Face Swapping.} Face swapping is also known as face replacement, which transfers a face from a source photo onto a face appearing in a target photo in order to generate a new genuine face.

<<<<<<< HEAD
The most early work for face swapping is \cite{exchface}. But the results are not that photorealistic. Later, the results are better \cite{de1,de2,de3,de4} and mainly used for deidentification. The main problem for face swapping is pose variation.
Many techniques solve this problem by using a 3D model \cite{3d1,de3,onseg}. Nirkin et al. \cite{onseg} transferred the face from source image onto target image using a 3D face model. They first detected facial landmarks that are used to establish 3D pose and facial expression for 3D face shape. Then they used a Fully Connected Network to segment the visible parts of faces from their contexts and occlusions. At last, source face is blended-in with the target context by using image seamless clone \cite{pie}. However, this step would fail when blending very different facial hues. Korshunova et al. \cite{faceswapping} proposed a network to generate a source face that could replace the face in the target image. The network only generate faces of the same type. For example, the net named CageNet only generate the face of Nicolas Cage. Those two methods mentioned above may greatly change the lightning condition of the face on the target image because they just transferred the source face onto the target image, but not contained any information of the target face. Bitouk et al. \cite{autorep} presented a system for automatic face replacement in images. Given a target face image, the system would retrieve a face with similar pose, lightning and color condition, then use such a face to replace the face on the target image. The limitation of this method is clear. The source face must have a similar pose and lightning condition with the target face.
%
The main difference between face swapping and our task is that we want to keep some features of the target face but not to replace the target face with the source face. In fact, how to fuse the features of the source face into the target face is our main consideration.
\cxj{So what is the difference between face fusion and face morphing?}
=======
The most early work for face swapping is \cite{exchface}. But the results are not that photorealistic. Later, the results are better \cite{de1,de2,de3,de4} and mainly used for deidentification. The main problem for face swapping is pose variation. 
Many techniques solve this problem by using a 3D model \cite{de3,3d1,onseg}. Nirkin et al. \cite{onseg} transferred the face from source image onto target image using a 3D face model. They first detected facial landmarks that are used to establish 3D pose and facial expression for 3D face shape. Then they used a Fully Connected Network to segment the visible parts of faces from their contexts and occlusions. At last, source face is blended-in with the target context by using image seamless clone \cite{pie}. However, this step would fail when blending very different facial hues. Korshunova et al. \cite{faceswapping} proposed a network to generate a source face that could replace the face in the target image. The network only generate faces of the same type. For example, the net named CageNet only generate the face of Nicolas Cage. Those two methods mentioned above may greatly change the lightning condition of the face on the target image because they just transferred the source face onto the target image, but not contained any information of the target face. Bitouk et al. \cite{autorep} presented a system for automatic face replacement in images. Given a target face image, the system would retrieve a face with similar pose, lightning and color condition, then use such a face to replace the face on the target image. The limitation of this method is clear. The source face must have a similar pose and lightning condition with the target face. 
%
The main difference between face swapping and our task is that we want to keep some features of the target face but not to replace the target face with the source face. In fact, how to fuse the features of the source face into the target face is our main consideration. 
\cxj{So what is the difference between face fusion and face morphing?}
>>>>>>> origin/master
